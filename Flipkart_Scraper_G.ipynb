{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf04088-e097-42b9-9ac2-c752bc65db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='scraper.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"a\", class_='wjcEIp')\n",
    "        title_string = title.text.strip() if title else \"Title Not Found\"\n",
    "    except AttributeError:\n",
    "        title_string = \"Title Not Found\"\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"div\", class_='Nx9bqj')\n",
    "        price_string = price.text.strip() if price else \"Price Not Found\"\n",
    "    except AttributeError:\n",
    "        price_string = \"Price Not Found\"\n",
    "    return price_string\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(\"div\", class_='XQDdHH')\n",
    "        rating_string = rating.text.strip() if rating else \"Rating Not Found\"\n",
    "    except AttributeError:\n",
    "        rating_string = \"Rating Not Found\"\n",
    "    return rating_string\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", class_='Wphh3N').text.strip()\n",
    "    except AttributeError:\n",
    "        review_count = \"Review Count Not Found\"\n",
    "    return review_count\n",
    "\n",
    "# Function to handle HTTP requests with retries\n",
    "def fetch_url(url, headers, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "            return response\n",
    "        except RequestException as e:\n",
    "            logging.error(f\"Request failed for URL {url} on attempt {attempt+1}: {e}\")\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "    logging.error(f\"All retries failed for URL: {url}\")\n",
    "    return None\n",
    "\n",
    "# Function to extract data from a single page\n",
    "def extract_data_from_page(url, headers):\n",
    "    page_data = {\"title\": [], \"price\": [], \"rating\": [], \"reviews\": []}\n",
    "    \n",
    "    webpage = fetch_url(url, headers)\n",
    "    if not webpage:\n",
    "        logging.error(f\"Failed to fetch the page URL: {url}\")\n",
    "        return page_data\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch product links\n",
    "    links = soup.find_all(\"a\", class_='VJA3rP')\n",
    "    links_list = [link.get('href') for link in links if link.get('href')]\n",
    "    \n",
    "    for link in links_list:\n",
    "        new_webpage = fetch_url(\"https://www.flipkart.com\" + link, headers)\n",
    "        if not new_webpage:\n",
    "            logging.error(f\"Failed to fetch product page for link: {link}\")\n",
    "            continue\n",
    "        \n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        page_data['title'].append(get_title(new_soup))\n",
    "        page_data['price'].append(get_price(new_soup))\n",
    "        page_data['rating'].append(get_rating(new_soup))\n",
    "        page_data['reviews'].append(get_review_count(new_soup))\n",
    "\n",
    "    return page_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    HEADERS = {'User-Agent': 'Your_User_Agent_Here', 'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    \n",
    "    # List of the first 4 pagination links\n",
    "    page_links = [\n",
    "        \"https://www.flipkart.com/search?q=Samsung+&otracker-search&otracker1=search&marketplace-FLIPKART&as-show-on&as=off&page=1\",\n",
    "        \"https://www.flipkart.com/search?q=Samsung+&otracker-search&otracker1-search&marketplace-FLIPKART&as-show=on&as-off&page=2\",\n",
    "        \"https://www.flipkart.com/search?q=Samsung+&otracker-search&otracker1-search&marketplace-FLIPKART&as-show=on&as-off&page=3\",\n",
    "        \"https://www.flipkart.com/search?q=Samsung+&otracker-search&otracker1-search&marketplace-FLIPKART&as-show=on&as=off&page=4\"\n",
    "    ]\n",
    "\n",
    "    all_data = {\"title\": [], \"price\": [], \"rating\": [], \"reviews\": []}\n",
    "\n",
    "    for page_url in page_links:\n",
    "        print(f\"Scraping URL: {page_url}...\")\n",
    "        page_data = extract_data_from_page(page_url, HEADERS)\n",
    "        \n",
    "        for key in all_data.keys():\n",
    "            all_data[key].extend(page_data[key])\n",
    "\n",
    "        # Delay to prevent rate limiting\n",
    "        time.sleep(5)  # Adjust this delay as needed\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    flipkart_df = pd.DataFrame.from_dict(all_data)\n",
    "\n",
    "    # Debug: Print number of rows in DataFrame\n",
    "    print(\"Number of rows in DataFrame:\", len(flipkart_df))\n",
    "\n",
    "    flipkart_df['title'].replace('', np.nan, inplace=True)\n",
    "    flipkart_df = flipkart_df.dropna(subset=['title'])\n",
    "    flipkart_df.to_csv(\"flipkart_data.csv\", header=True, index=False)\n",
    "\n",
    "    print('Data has been successfully written to flipkart_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
